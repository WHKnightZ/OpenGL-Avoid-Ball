{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import socket\n",
    "import struct\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [[1.0, 0, 0], [0, 1.0, 0], [0, 0, 1.0]]\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "data = np.array(df)\n",
    "\n",
    "x = data[:, :6700]\n",
    "y = data[:, 6700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(54202, 6700)\n",
    "y = np.array([lst[int(i)] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(6700, )))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "epochs = 25\n",
    "lr = 0.02\n",
    "decay = lr / epochs\n",
    "sgd = SGD(lr=lr, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.fit(x, y, batch_size=32, epochs=epochs)\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.argmax(model.predict_on_batch(np.random.rand(1, 6700)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train from realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def __init__(self):\n",
    "        self.UDP_IP = \"127.0.0.1\"\n",
    "        self.UDP_PORT_RECV = 9003\n",
    "        self.UDP_PORT_SEND = 9004\n",
    "\n",
    "        self.send = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "        self.recv = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "        self.recv.bind((self.UDP_IP, self.UDP_PORT_RECV))\n",
    "\n",
    "    def reset(self):\n",
    "        self.send.sendto(struct.pack(\"i\", -1), (self.UDP_IP, self.UDP_PORT_SEND))\n",
    "        data, _ = self.recv.recvfrom(26808)\n",
    "        data = np.array(struct.unpack('6702f', data))[:6700]\n",
    "        return data.reshape(1, 6700)\n",
    "\n",
    "    def step(self, action):\n",
    "        self.send.sendto(struct.pack(\"i\", action), (self.UDP_IP, self.UDP_PORT_SEND))\n",
    "        data, _ = self.recv.recvfrom(26808)\n",
    "        data = np.array(struct.unpack('6702f', data))\n",
    "        new_state = data[:6700].reshape(1, 6700)\n",
    "        reward = data[6700]\n",
    "        lose = True if data[6701] > 0 else False\n",
    "        return new_state, reward, lose\n",
    "\n",
    "env = Env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_decay = 0.05\n",
    "        self.epsilon_min = 0.01\n",
    "        lr = 0.001\n",
    "        decay = 0.01 / 25\n",
    "        self.sgd = SGD(lr=lr, momentum=0.9, decay=decay, nesterov=False)\n",
    "        self.replay_buffer = deque(maxlen=20000)\n",
    "        self.train_network = self.create_model()\n",
    "        self.episode_num = 400\n",
    "        self.num_pick_from_buffer = 32\n",
    "        self.target_network = self.create_model()\n",
    "        self.target_network.set_weights(self.train_network.get_weights())\n",
    "\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, activation='relu', input_shape=(6700, )))\n",
    "        model.add(Dense(128, activation='relu', input_shape=(6700, )))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=self.sgd, metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_best_action(self, state):\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
    "        if np.random.rand(1) < self.epsilon:\n",
    "            action = np.random.randint(0, 3)\n",
    "        else:\n",
    "            action = np.argmax(self.train_network.predict(state)[0])\n",
    "        return action\n",
    "\n",
    "    def train_from_buffer(self):\n",
    "        if len(self.replay_buffer) < self.num_pick_from_buffer:\n",
    "            return\n",
    "        samples = random.sample(self.replay_buffer, self.num_pick_from_buffer)\n",
    "        states = []\n",
    "        new_states = []\n",
    "        for sample in samples:\n",
    "            state, action, reward, new_state, done = sample\n",
    "            states.append(state)\n",
    "            new_states.append(new_state)\n",
    "\n",
    "        new_array = np.array(states)\n",
    "        states = new_array.reshape(self.num_pick_from_buffer, 6700)\n",
    "        new_array2 = np.array(new_states)\n",
    "        new_states = new_array2.reshape(self.num_pick_from_buffer, 6700)\n",
    "        targets = self.train_network.predict(states)\n",
    "        new_state_targets = self.target_network.predict(new_states)\n",
    "\n",
    "        i = 0\n",
    "        for sample in samples:\n",
    "            state, action, reward, new_state, done = sample\n",
    "            target = targets[i]\n",
    "            if done:\n",
    "                target[action] = reward\n",
    "            else:\n",
    "                Q_future = max(new_state_targets[i])\n",
    "                target[action] = reward + Q_future * self.gamma\n",
    "            i += 1\n",
    "\n",
    "        self.train_network.fit(states, targets, epochs=1, verbose=0)\n",
    "\n",
    "    def original_try(self, current_state, eps):\n",
    "        reward_sum = 0\n",
    "        iteration = 0\n",
    "\n",
    "        while True:\n",
    "            best_action = self.get_best_action(current_state)\n",
    "            new_state, reward, lose = self.env.step(best_action)\n",
    "            done = False\n",
    "            if reward > 0.8:\n",
    "                done = True\n",
    "            if iteration > 30:\n",
    "                self.replay_buffer.append([current_state, best_action, reward, new_state, done])\n",
    "            self.train_from_buffer()\n",
    "            reward_sum += reward\n",
    "            current_state = new_state\n",
    "            \n",
    "            iteration +=1\n",
    "            \n",
    "            if lose:\n",
    "                break\n",
    "\n",
    "        self.target_network.set_weights(self.train_network.get_weights())\n",
    "\n",
    "        print(f\"ep: {eps}, epsilon: {self.epsilon}, iteration: {iteration}, reward: {reward_sum}\")\n",
    "        self.epsilon -= self.epsilon_decay\n",
    "        if self.epsilon < self.epsilon_min:\n",
    "            self.epsilon = self.epsilon_min\n",
    "\n",
    "    def start(self):\n",
    "        for eps in range(self.episode_num):\n",
    "            current_state = self.env.reset()\n",
    "            self.original_try(current_state, eps)\n",
    "\n",
    "\n",
    "train = Train(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.train_network.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.send.close()\n",
    "env.recv.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model.h5\")\n",
    "\n",
    "UDP_IP = \"127.0.0.1\"\n",
    "UDP_PORT_RECV = 9003\n",
    "UDP_PORT_SEND = 9004\n",
    "\n",
    "\n",
    "send = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "recv = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "recv.bind((UDP_IP, UDP_PORT_RECV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send.sendto(struct.pack(\"i\", -1), (UDP_IP, UDP_PORT_SEND))\n",
    "\n",
    "while True:\n",
    "    data, addr = recv.recvfrom(26808)\n",
    "    print('x')\n",
    "    inp = struct.unpack('6702f', data)[:6700]\n",
    "    inp = np.array(inp).reshape(1, 6700)\n",
    "    ret = model.predict(inp)\n",
    "    ret = np.argmax(ret[0])\n",
    "    send.sendto(struct.pack(\"i\", ret), (UDP_IP, UDP_PORT_SEND))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
